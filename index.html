<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Downtime OCR — Capture + Bounding Boxes + Crop</title>
  <style>
    body { font-family: system-ui, sans-serif; margin: 12px; color:#111 }
    #cameraWrap { position: relative; width: 100%; max-width:720px; margin-bottom:8px; }
    video, canvas#overlay { width: 100%; height: auto; display:block; border: 1px solid #ccc; background:#000; }
    #controls { margin: 8px 0; display:flex; gap:8px; flex-wrap:wrap; }
    button { padding:8px 10px; }
    #preview { max-width: 300px; display:none; border:1px solid #ddd; margin-top:8px; }
    .box { position:absolute; border:2px dashed rgba(0,200,50,0.8); pointer-events:none }
    #rows { margin-top:12px; width:100%; max-width:900px; }
    table { width:100%; border-collapse: collapse; margin-top:8px; }
    th,td { border:1px solid #ddd; padding:6px; text-align:left; font-size:13px; }
    td [contenteditable] { min-width:40px; display:inline-block; }
    #status { margin-top:10px; color:#444 }
  </style>
</head>
<body>
  <h1>Downtime OCR — Capture + Boxes + Crop</h1>

  <div id="cameraWrap">
    <video id="video" autoplay playsinline></video>
    <canvas id="overlay"></canvas>
  </div>

  <div id="controls">
    <select id="machineSelect">
      <option>ML1</option><option>ML2</option><option>ML3</option><option>ML4</option>
      <option>ML5</option><option>ML6</option><option>ML7</option><option>ML8</option>
    </select>
    <button id="captureBtn">Capture Frame</button>
    <button id="detectBtn" disabled>Detect Text (OCR)</button>
    <button id="cropBtn" disabled>Crop Selected / Freeform & OCR</button>
    <button id="clearBoxesBtn">Clear Boxes</button>
    <button id="downloadCsv">Download CSV</button>
  </div>

  <img id="preview" alt="crop preview" />

  <div id="status">Status: idle</div>

  <div id="rows">
    <table id="dataTable">
      <thead>
        <tr><th>Machine</th><th>Down Time</th><th>Reason</th><th>Occurrence</th><th>Operator</th><th>Action</th></tr>
      </thead>
      <tbody id="tbody"></tbody>
    </table>
  </div>

  <!-- Tesseract.js from CDN -->
  <script src="https://unpkg.com/tesseract.js@2.1.5/dist/tesseract.min.js"></script>

  <script>
  // ----------------------------
  // Basic page elements & state
  // ----------------------------
  const video = document.getElementById('video');
  const overlay = document.getElementById('overlay');
  const ctxOverlay = overlay.getContext('2d');
  const captureBtn = document.getElementById('captureBtn');
  const detectBtn = document.getElementById('detectBtn');
  const cropBtn = document.getElementById('cropBtn');
  const clearBoxesBtn = document.getElementById('clearBoxesBtn');
  const preview = document.getElementById('preview');
  const status = document.getElementById('status');
  const machineSelect = document.getElementById('machineSelect');
  const tbody = document.getElementById('tbody');
  const downloadCsv = document.getElementById('downloadCsv');

  // canvas for captured frame & cropping
  const captureCanvas = document.createElement('canvas');
  const captureCtx = captureCanvas.getContext('2d');

  // OCR worker
  const { createWorker } = Tesseract;
  const worker = createWorker({
    logger: m => { /* optionally show progress: console.log(m) */ }
  });

  // Detected boxes from tesseract (coords relative to image pixels)
  let detectedBoxes = []; // {x,y,w,h, text, confidence}
  // Current selection rectangle in overlay coordinates (css pixel space)
  let selection = null; 
  let isDrawing = false, startX=0, startY=0;
  let lastImageBlob = null; // blob of last captured frame (preprocessed)

  // DB: simple localStorage with key
  const DB_KEY = 'downtime_rows_v1';
  function loadRows(){ return JSON.parse(localStorage.getItem(DB_KEY) || '[]'); }
  function saveRows(rows){ localStorage.setItem(DB_KEY, JSON.stringify(rows)); }

  // ----------------------------
  // Start camera (mobile friendly)
  // ----------------------------
  async function startCamera(){
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" }, audio: false });
      video.srcObject = stream;
      await video.play();
      // size overlay to match video display size
      resizeOverlay();
      window.addEventListener('resize', resizeOverlay);
    } catch (e) {
      status.textContent = 'ERROR starting camera: ' + e.message;
    }
  }

  function resizeOverlay(){
    // make overlay same displayed size as video
    overlay.width = video.clientWidth;
    overlay.height = video.clientHeight;
    drawClearOverlay();
  }

  function drawClearOverlay(){
    ctxOverlay.clearRect(0,0,overlay.width, overlay.height);
    // optionally draw guide grid
    ctxOverlay.strokeStyle = 'rgba(255,255,255,0.06)';
    ctxOverlay.lineWidth = 1;
    // no further drawing here; boxes drawn by drawBoxes()
  }

  // ----------------------------
  // Capture frame to offscreen canvas & preprocess
  // ----------------------------
  function captureFrame(){
    // compute natural size from video track settings
    const vw = video.videoWidth;
    const vh = video.videoHeight;
    if(!vw || !vh){ status.textContent = 'Video not ready'; return; }
    captureCanvas.width = vw;
    captureCanvas.height = vh;
    captureCtx.drawImage(video, 0, 0, vw, vh);
    // optional preprocessing: upscale + grayscale + simple threshold
    // (we will return a blob)
    return new Promise(resolve => {
      // toBlob yields PNG
      captureCanvas.toBlob(blob => {
        lastImageBlob = blob;
        const url = URL.createObjectURL(blob);
        preview.src = url;
        preview.style.display = 'block';
        status.textContent = 'Captured frame';
        detectBtn.disabled = false;
        resolve(blob);
      }, 'image/png');
    });
  }

  // ----------------------------
  // Helper: map tesseract bbox coords -> overlay css coords
  // Tesseract returns coords relative to the image natural size (captureCanvas size)
  // Need to scale them to overlay.clientWidth / clientHeight
  // ----------------------------
  function imageToOverlayCoords(box, imageWidth, imageHeight){
    const scaleX = overlay.width / imageWidth;
    const scaleY = overlay.height / imageHeight;
    return {
      x: Math.round(box.x0 * scaleX),
      y: Math.round(box.y0 * scaleY),
      w: Math.round((box.x1 - box.x0) * scaleX),
      h: Math.round((box.y1 - box.y0) * scaleY)
    };
  }

  // ----------------------------
  // Run OCR on captured frame and collect boxes
  // ----------------------------
  async function detectTextOnCaptured(){
    if(!lastImageBlob){ status.textContent = 'No captured image. Press Capture'; return; }
    status.textContent = 'Initializing OCR worker (may take a few seconds)...';
    await worker.load();
    await worker.loadLanguage('eng');
    await worker.initialize('eng');
    status.textContent = 'Running OCR on captured image...';
    const { data } = await worker.recognize(lastImageBlob);
    // data.words contains words with bounding boxes
    detectedBoxes = [];
    const iw = captureCanvas.width, ih = captureCanvas.height;
    if(data && data.words && data.words.length){
      for(const w of data.words){
        const box = { x0: w.bbox.x0, y0: w.bbox.y0, x1: w.bbox.x1, y1: w.bbox.y1 };
        const overlayBox = imageToOverlayCoords(box, iw, ih);
        detectedBoxes.push({ imageBox: box, overlayBox, text: w.text, conf: w.confidence || w.conf });
      }
    } else {
      status.textContent = 'No text detected (try a clearer photo)';
    }
    drawBoxes();
    cropBtn.disabled = false;
    status.textContent = `Detected ${detectedBoxes.length} boxes. Click a box to select it, or draw a freeform box.`;
  }

  // Draw detection boxes on overlay
  function drawBoxes(){
    drawClearOverlay();
    ctxOverlay.lineWidth = 2;
    for(let i=0;i<detectedBoxes.length;i++){
      const b = detectedBoxes[i].overlayBox;
      ctxOverlay.strokeStyle = 'rgba(0,200,120,0.9)';
      ctxOverlay.strokeRect(b.x, b.y, b.w, b.h);
      ctxOverlay.fillStyle = 'rgba(0,200,120,0.9)';
      ctxOverlay.font = '12px sans-serif';
      const txt = (detectedBoxes[i].text || '').slice(0,20);
      ctxOverlay.fillText(txt, b.x + 2, Math.max(b.y - 4, 12));
    }
    // If selection active, draw it
    if(selection){
      ctxOverlay.strokeStyle = 'rgba(255,80,80,0.95)';
      ctxOverlay.lineWidth = 3;
      ctxOverlay.strokeRect(selection.x, selection.y, selection.w, selection.h);
    }
  }

  // ----------------------------
  // Clicking on overlay chooses nearest detection box
  // Also allow freeform draw (mousedown/touchstart)
  // ----------------------------
  overlay.addEventListener('mousedown', (e)=>{
    const rect = overlay.getBoundingClientRect();
    const x = e.clientX - rect.left;
    const y = e.clientY - rect.top;

    // check if clicked inside detected box -> select it
    let found = null;
    for(const b of detectedBoxes){
      const bb = b.overlayBox;
      if(x >= bb.x && x <= bb.x + bb.w && y >= bb.y && y <= bb.y + bb.h){
        found = b; break;
      }
    }
    if(found){
      // set selection to that box
      selection = { x: found.overlayBox.x, y: found.overlayBox.y, w: found.overlayBox.w, h: found.overlayBox.h };
      drawBoxes();
      status.textContent = 'Selected detected box: "' + (found.text||'') + '"';
    } else {
      // start a freeform selection
      isDrawing = true;
      startX = x; startY = y;
      selection = { x: x, y: y, w: 0, h: 0 };
      drawBoxes();
    }
  });

  overlay.addEventListener('mousemove', (e)=>{
    if(!isDrawing) return;
    const rect = overlay.getBoundingClientRect();
    const x = e.clientX - rect.left;
    const y = e.clientY - rect.top;
    selection.x = Math.min(startX, x);
    selection.y = Math.min(startY, y);
    selection.w = Math.abs(x - startX);
    selection.h = Math.abs(y - startY);
    drawBoxes();
  });

  overlay.addEventListener('mouseup', (e)=>{
    if(isDrawing){ isDrawing = false; drawBoxes(); status.textContent = 'Freeform box drawn. Press "Crop Selected / Freeform & OCR"'; }
  });

  // Touch support for mobile
  overlay.addEventListener('touchstart', (e)=>{
    e.preventDefault();
    const t = e.touches[0];
    const rect = overlay.getBoundingClientRect();
    startX = t.clientX - rect.left; startY = t.clientY - rect.top;
    isDrawing = true;
    selection = { x: startX, y: startY, w: 0, h: 0 };
  }, { passive:false });

  overlay.addEventListener('touchmove', (e)=>{
    if(!isDrawing) return;
    const t = e.touches[0];
    const rect = overlay.getBoundingClientRect();
    const x = t.clientX - rect.left; const y = t.clientY - rect.top;
    selection.x = Math.min(startX, x);
    selection.y = Math.min(startY, y);
    selection.w = Math.abs(x - startX);
    selection.h = Math.abs(y - startY);
    drawBoxes();
  }, { passive:false });

  overlay.addEventListener('touchend', (e)=>{
    isDrawing = false;
    drawBoxes();
    status.textContent = 'Freeform box drawn. Press "Crop Selected / Freeform & OCR"';
  });

  // ----------------------------
  // Crop the selection (overlay coords -> image coords) and OCR that region
  // ----------------------------
  async function cropAndRecognize(){
    if(!selection || !lastImageBlob){ status.textContent = 'No selection or no captured image'; return; }
    // Map overlay selection back to captureCanvas image coordinates
    const iw = captureCanvas.width, ih = captureCanvas.height;
    const sx = Math.round(selection.x * (iw / overlay.width));
    const sy = Math.round(selection.y * (ih / overlay.height));
    const sw = Math.round(selection.w * (iw / overlay.width));
    const sh = Math.round(selection.h * (ih / overlay.height));
    if(sw <=0 || sh <=0){ status.textContent='Invalid crop region'; return; }

    // create temporary canvas with crop
    const tmp = document.createElement('canvas');
    tmp.width = sw; tmp.height = sh;
    const tctx = tmp.getContext('2d');

    // draw current capture image into canvas (we have captureCanvas)
    const img = new Image();
    img.onload = async () => {
      tctx.drawImage(img, sx, sy, sw, sh, 0, 0, sw, sh);
      // show preview
      tmp.toBlob(async blob=>{
        preview.src = URL.createObjectURL(blob);
        preview.style.display = 'block';
        status.textContent = 'OCR cropping...';
        // run tesseract on the cropped blob
        const { data } = await worker.recognize(blob);
        const text = (data && data.text) ? data.text.trim() : '';
        status.textContent = `Cropped OCR result: "${text.replace(/\s+/g,' ')}" (press Assign)`;
        // Offer quick assign UI: append row or assign to a column
        showAssignUI(text);
      }, 'image/png');
    };
    // produce image from captureCanvas to load into img
    img.src = captureCanvas.toDataURL();
  }

  // Show assign UI: minimal — create a new row prefilled and let user edit
  function showAssignUI(text){
    // We'll populate a new row in the table with selected machine and OCR text in Down Time cell by default.
    // You can edit cells before saving.
    const newRow = { machine: machineSelect.value, downTime: text, reason:'', occurrence:'', operator:'' };
    const rows = loadRows();
    rows.push(newRow);
    saveRows(rows);
    renderTable();
    status.textContent = 'OCR text appended to table (editable).';
  }

  // ----------------------------
  // UI: populate table from localStorage & edit/save rows
  // ----------------------------
  function renderTable(){
    const rows = loadRows();
    tbody.innerHTML = '';
    rows.forEach((r, idx) => {
      const tr = document.createElement('tr');
      tr.innerHTML = `
        <td>${escapeHtml(r.machine)}</td>
        <td contenteditable="true" data-field="downTime">${escapeHtml(r.downTime)}</td>
        <td contenteditable="true" data-field="reason">${escapeHtml(r.reason)}</td>
        <td contenteditable="true" data-field="occurrence">${escapeHtml(r.occurrence)}</td>
        <td contenteditable="true" data-field="operator">${escapeHtml(r.operator)}</td>
        <td><button data-idx="${idx}" class="saveRow">Save</button> <button data-idx="${idx}" class="delRow">Delete</button></td>
      `;
      tbody.appendChild(tr);
    });
  }

  // helper to escape
  function escapeHtml(s=''){ return (s+'').replace(/[&<>"']/g, c=> ({'&':'&amp;','<':'&lt;','>':'&gt;','"':'&quot;',"'":'&#39;'}[c])); }

  // Save on Save button click
  tbody.addEventListener('click', (e)=>{
    const target = e.target;
    if(target.classList.contains('saveRow')){
      const idx = Number(target.dataset.idx);
      const tr = target.closest('tr');
      const cells = tr.querySelectorAll('td[contenteditable]');
      const rows = loadRows();
      rows[idx].downTime = cells[0].textContent.trim();
      rows[idx].reason = cells[1].textContent.trim();
      rows[idx].occurrence = cells[2].textContent.trim();
      rows[idx].operator = cells[3].textContent.trim();
      saveRows(rows);
      status.textContent = 'Row saved';
      renderTable();
    } else if(target.classList.contains('delRow')){
      const idx = Number(target.dataset.idx);
      const rows = loadRows();
      rows.splice(idx,1);
      saveRows(rows);
      renderTable();
    }
  });

  // Download CSV
  downloadCsv.addEventListener('click', ()=>{
    const rows = loadRows();
    if(!rows.length){ status.textContent = 'No rows to download'; return; }
    const hdr = ['Machine','Down Time','Reason','Occurrence','Operator'];
    const csv = [hdr.join(',')].concat(rows.map(r => 
      [r.machine, r.downTime, r.reason, r.occurrence, r.operator].map(cell => `"${(cell||'').replace(/"/g,'""')}"`).join(',')
    )).join('\n');
    const blob = new Blob([csv], { type: 'text/csv' });
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url; a.download = 'downtime.csv'; document.body.appendChild(a); a.click(); a.remove();
    status.textContent = 'CSV downloaded';
  });

  // helpers
  captureBtn.addEventListener('click', async ()=> {
    await captureFrame();
    // draw a frozen preview on overlay for clarity
    const img = new Image();
    img.onload = ()=>{
      // draw captured image scaled to overlay to give users background for selection
      drawClearOverlay();
      ctxOverlay.drawImage(img, 0, 0, overlay.width, overlay.height);
      status.textContent = 'Frame captured. Click detect to detect boxes or draw a box.';
    };
    img.src = URL.createObjectURL(lastImageBlob);
  });

  detectBtn.addEventListener('click', detectTextOnCaptured);
  cropBtn.addEventListener('click', cropAndRecognize);
  clearBoxesBtn.addEventListener('click', ()=>{ detectedBoxes=[]; selection=null; drawClearOverlay(); status.textContent='Cleared boxes'; });

  // init
  (async function init(){
    renderTable();
    await startCamera();
    status.textContent = 'Camera started. Press Capture to take photo.';
  })();

  // release worker when leaving
  window.addEventListener('beforeunload', async ()=>{
    try { await worker.terminate(); } catch(e) {}
  });

  </script>
</body>
</html>
